{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HomemadeDataset2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKN5_Pv1H9jf"
      },
      "source": [
        "!git clone https://github.com/joren015/ASLRecognition.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ0hYFP5IAbK"
      },
      "source": [
        "!cp -r /content/ASLRecognition/Datasets /content\r\n",
        "!cp /content/ASLRecognition/Functions.py /content\r\n",
        "!cp /content/ASLRecognition/Model.py /content\r\n",
        "!cp /content/ASLRecognition/NotebookUtils.py /content"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5A5uYOqICy7"
      },
      "source": [
        "!pip install mediapipe==0.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF-p9MrDIEv1"
      },
      "source": [
        "from NotebookUtils import PrintDatetime\r\n",
        "PrintDatetime(\"Importing packages\")\r\n",
        "import itertools  \r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import mediapipe as mp\r\n",
        "import shutil\r\n",
        "from os import walk, makedirs, listdir, cpu_count, environ\r\n",
        "from os.path import join, exists, isfile, join\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from Functions import *\r\n",
        "from Model import *\r\n",
        "PrintDatetime()\r\n",
        "\r\n",
        "\r\n",
        "root_dir = \"/content\"\r\n",
        "dataset_path = \"{}/Datasets\".format(root_dir)\r\n",
        "if not exists(root_dir):\r\n",
        "  makedirs(root_dir)\r\n",
        "\r\n",
        "try:\r\n",
        "  shutil.rmtree(root_dir + \"/Datasets/silver\")\r\n",
        "  shutil.rmtree(root_dir + \"/Datasets/gold\")\r\n",
        "except OSError as e:\r\n",
        "  print(\"Error: %s : %s\" % (root_dir, e.strerror))\r\n",
        "\r\n",
        "directories = [\"{}/models\", \"{}/Datasets/bronze/homemade_dataset2\", \"{}/Datasets/silver/homemade_dataset2\", \"{}/Datasets/silver/homemade_dataset2_cropped/center_2\", \"{}/Datasets/silver/homemade_dataset2_resized/center_2\", \"{}/Datasets/gold/Homography\", \"{}/Datasets/gold/Censure\", \"{}/Datasets/gold/Transforms\", \"{}/Datasets/gold/homemade_dataset2_resized/center_2\", \"{}/Datasets/gold/homemade_dataset2_transformed/center_2/\"]\r\n",
        "directories = [x.format(root_dir) for x in directories]\r\n",
        "for d in directories:\r\n",
        "  if not exists(d):\r\n",
        "    makedirs(d)\r\n",
        "\r\n",
        "\r\n",
        "starting_data = {\"./Datasets/HomemadeDataset2/center_2.mp4\": \"{}/bronze/homemade_dataset2/center_2.mp4\".format(dataset_path), \"./Datasets/HomemadeDataset2/center_2.csv\": \"{}/bronze/homemade_dataset2/center_2.csv\".format(dataset_path)}\r\n",
        "for k,v in starting_data.items():\r\n",
        "  if not exists(v):\r\n",
        "    shutil.copyfile(k, v)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_test_path_base = \"{}/gold\".format(dataset_path)\r\n",
        "alpha_num = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\r\n",
        "encoding_config = {\"a\": 0, \"b\": 1,\"c\": 2,\"d\": 3,\"e\": 4,\"f\": 5,\"g\": 6,\"h\": 7\r\n",
        "                   ,\"i\": 8,\"j\": 9,\"k\": 10,\"l\": 11,\"m\": 12,\"n\": 13,\"o\": 14\r\n",
        "                   ,\"p\": 15,\"q\": 16,\"r\": 17,\"s\": 18,\"t\": 19,\"u\": 20,\"v\": 21\r\n",
        "                   ,\"w\": 22,\"x\": 23,\"y\": 24,\"z\": 25,\"0\": 26,\"1\": 27,\"2\": 28\r\n",
        "                   ,\"3\": 29,\"4\": 30,\"5\": 31,\"6\": 32,\"7\": 33,\"8\": 34,\"9\": 35 }\r\n",
        "PrintDatetime()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "PrintDatetime(\"Started extracting video dataset\")\r\n",
        "video_dir_load = dataset_path + \"/bronze/homemade_dataset2\"\r\n",
        "labels_dir_load = dataset_path + \"/bronze/homemade_dataset2\"\r\n",
        "file_list = [\"{}/{}\".format(video_dir_load, x) for x in listdir(video_dir_load) if '.mp4' in x and 'center' in x]\r\n",
        "mp_drawing = mp.solutions.drawing_utils\r\n",
        "mp_hands = mp.solutions.hands\r\n",
        "hands = mp_hands.Hands(min_detection_confidence=0.7, max_num_hands=1, static_image_mode=False, min_tracking_confidence=0.5)\r\n",
        "for f in file_list:\r\n",
        "  print(f)\r\n",
        "  file_name = f.split('/')[-1]\r\n",
        "  file_name_no_ext = file_name.split('.')[0]\r\n",
        "  output_file_path = '/'.join(f.split('/')[0:-1] + [file_name_no_ext]).replace(\"bronze\", \"silver\")\r\n",
        "  if not exists(output_file_path):\r\n",
        "    makedirs(output_file_path)\r\n",
        "\r\n",
        "  labels_path = \"{}/{}.csv\".format(labels_dir_load, file_name_no_ext)\r\n",
        "  labels = pd.read_csv(labels_path)\r\n",
        "  rotate_video = False\r\n",
        "  if \"center\" in file_name:\r\n",
        "    rotate_video = True\r\n",
        "\r\n",
        "  vid = cv2.VideoCapture(f)\r\n",
        "  count_frame = 0\r\n",
        "  label_i = '-'\r\n",
        "  while(vid.isOpened()):\r\n",
        "    ret, frame = vid.read()\r\n",
        "    if ret:\r\n",
        "      subset = labels[(labels['frame_start'] <= count_frame) & (labels['frame_end'] > count_frame)]\r\n",
        "      if len(subset) == 1:\r\n",
        "        label_i = subset.iloc[0]['label']\r\n",
        "      elif len(subset) == 0:\r\n",
        "        label_i = '-'\r\n",
        "      else:\r\n",
        "        print(\"SOMETHING WENT WRONG\")\r\n",
        "\r\n",
        "      if rotate_video:\r\n",
        "        frame = cv2.rotate(frame, cv2.ROTATE_180)\r\n",
        "\r\n",
        "      if label_i != \"-\":\r\n",
        "        export_file = \"{}/{}_{}_{}\".format(output_file_path, file_name_no_ext, label_i, count_frame)\r\n",
        "        cv2.imwrite(export_file + \".png\", frame)\r\n",
        "        image = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\r\n",
        "        image.flags.writeable = False\r\n",
        "        results = hands.process(image)\r\n",
        "        image.flags.writeable = True\r\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
        "        if results.multi_hand_landmarks:\r\n",
        "          for hand_landmarks in results.multi_hand_landmarks:\r\n",
        "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\r\n",
        "            landmark_matrix = np.zeros((21,3))\r\n",
        "            i = 0\r\n",
        "            for h in hand_landmarks.landmark:\r\n",
        "              landmark_matrix[:][i] = np.array([h.x, h.y, h.z])\r\n",
        "              i += 1\r\n",
        "\r\n",
        "            torch.save(torch.from_numpy(landmark_matrix), export_file + \"_landmarks.pt\")\r\n",
        "        \r\n",
        "        # cv2.imshow('MediaPipe Hands', image)\r\n",
        "      \r\n",
        "      count_frame += 1\r\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
        "        break\r\n",
        "\r\n",
        "    else:\r\n",
        "      break\r\n",
        "\r\n",
        "  vid.release()\r\n",
        "  cv2.destroyAllWindows()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGHaEcAgZvE4"
      },
      "source": [
        "PrintDatetime(\"Started cropping video dataset\")\r\n",
        "letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\r\n",
        "dirs = [\"center_2\"]\r\n",
        "for i in dirs:\r\n",
        "  image_dir = \"{}/silver/homemade_dataset2/{}/\".format(dataset_path, i)\r\n",
        "  file_list = [\"{}{}\".format(image_dir, x) for x in listdir(image_dir) if \".png\" in x]\r\n",
        "  save_dir = \"{}/silver/homemade_dataset2_cropped/{}\".format(dataset_path, i)\r\n",
        "  for l in letters:\r\n",
        "    sub_list = [x for x in file_list if x.split('/')[-1].split('_')[2] == l]\r\n",
        "\r\n",
        "    for idx, file in enumerate(sub_list):\r\n",
        "      file_name = file.split('/')[-1]\r\n",
        "      landmarks_path = '/'.join(file.split('.')[0:-1]) + \"_landmarks.pt\"\r\n",
        "      if not exists(landmarks_path):\r\n",
        "        print(\"No landmarks\")\r\n",
        "        MPLoop([file], \"{}/misc/\".format(root_dir), file.replace(file_name, \"\"))\r\n",
        "        points = GetPoints(file, landmarks_path)\r\n",
        "      else:\r\n",
        "        points = GetPoints(file, landmarks_path)\r\n",
        "      \r\n",
        "      min_x = int(np.min(points[:,0]))-50\r\n",
        "      max_x = int(np.max(points[:,0]))+50\r\n",
        "      min_y = int(np.min(points[:,1]))-100\r\n",
        "      max_y = int(np.max(points[:,1]))+100\r\n",
        "      img = plt.imread(file)\r\n",
        "      img_cropped = img[min_y:max_y,min_x:max_x,:]\r\n",
        "      h,w,x = img_cropped.shape\r\n",
        "      points[:,0] = points[:,0] - min_x\r\n",
        "      points[:,1] = points[:,1] - min_y\r\n",
        "      reverted_points = np.zeros([21,3])\r\n",
        "      reverted_points[:,0] = (w/2 - points[:,0] + w/2)/w\r\n",
        "      reverted_points[:,1] = points[:,1]/h\r\n",
        "      torch.save(torch.from_numpy(reverted_points), landmarks_path.replace(\"silver/homemade_dataset2\", \"gold/homemade_dataset2_resized\"))\r\n",
        "      plt.imsave(\"{}/{}\".format(save_dir, file_name), img_cropped)\r\n",
        "      # plt.imshow(img_cropped)\r\n",
        "      # plt.show()\r\n",
        "\r\n",
        "PrintDatetime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAhH_CDbZsue"
      },
      "source": [
        "PrintDatetime(\"Started resizing video dataset\")\r\n",
        "PreprocessDatasets(\"{}/silver/homemade_dataset2_cropped/center_2\".format(dataset_path), \"{}/gold/homemade_dataset2_resized/center_2\".format(dataset_path), \".png\", overwrite=True)\r\n",
        "PrintDatetime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBQm84xBZoFX"
      },
      "source": [
        "PrintDatetime(\"Started determining new baseline\")\r\n",
        "baseline_results_path = \"{}/bronze/homemade_dataset2\".format(dataset_path)\r\n",
        "DetermineNewBaseline(\"{}/gold/homemade_dataset2_resized/center_2\".format(dataset_path), baseline_results_path, is_still=False)\r\n",
        "PrintDatetime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og7tRtHUZlxK"
      },
      "source": [
        "PrintDatetime(\"Started transforming video dataset\")\r\n",
        "baseline2 = NewBaseline(baseline_results_path + \"/baseline_eval_homography_homemade_dataset.json\", is_still=False)\r\n",
        "dirs = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\r\n",
        "results = {c: {} for c in dirs}\r\n",
        "transform = \"homography\"\r\n",
        "for c in dirs:\r\n",
        "  image_paths = []\r\n",
        "  image_dir = \"{}/gold/homemade_dataset2_resized/center_2\".format(dataset_path)\r\n",
        "  image_paths += [\"{}/{}\".format(image_dir, x) for x in listdir(image_dir) if x.split('.')[-1] == \"png\" and x.split(\"_\")[2] == c]\r\n",
        "  baseline_img_path = [x for x in baseline2 if x.split('/')[-1].split('_')[2] == c][0]\r\n",
        "  baseline_fp_path = baseline_img_path.replace(\".png\", \"_landmarks.pt\")\r\n",
        "  baseline_img = cv2.imread(baseline_img_path)\r\n",
        "  baseline_fp = GetPoints(baseline_img_path, baseline_fp_path)\r\n",
        "  for img_path in image_paths:\r\n",
        "    if img_path != baseline_img_path:\r\n",
        "      img_fp_path = img_path.replace(\".png\", \"_landmarks.pt\")\r\n",
        "      img = cv2.imread(img_path)\r\n",
        "      img_fp = GetPoints(img_path, img_fp_path)\r\n",
        "      img_transformed = HomographyTransform(img, baseline_img, img_fp, baseline_fp)\r\n",
        "      cv2.imwrite(img_path.replace(\"homemade_dataset2_resized\", \"homemade_dataset2_transformed\"), img_transformed)\r\n",
        "      torch.save(torch.from_numpy(img_transformed.reshape(3, 200, 200)), img_path.replace(\"homemade_dataset2_resized\", \"homemade_dataset2_transformed\").replace(\".png\", \".pt\"))\r\n",
        "      \r\n",
        "\r\n",
        "  print(\"Character: {}\".format(c))\r\n",
        "\r\n",
        "PrintDatetime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI4_n8KiZjvv"
      },
      "source": [
        "PrintDatetime(\"Started labeling non-transformed video data\")\r\n",
        "LabelDatasets(load_path=\"{}/gold/homemade_dataset2_resized\".format(dataset_path), save_path=\"{}/gold/homemade_dataset2_resized\".format(dataset_path), encoding_config=encoding_config)\r\n",
        "PrintDatetime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouIeKUlFZh2g"
      },
      "source": [
        "PrintDatetime(\"Started labeling transformed video data\")\r\n",
        "LabelDatasets(load_path=\"{}/gold/homemade_dataset2_transformed\".format(dataset_path), save_path=\"{}/gold/homemade_dataset2_transformed\".format(dataset_path), encoding_config=encoding_config)\r\n",
        "PrintDatetime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvoxgq3EZf_Z"
      },
      "source": [
        "PrintDatetime(\"Started training\")\n",
        "hpt = {\"learning_rate\": [1e-2, 1e-4, 1e-5], \"batch_size\": [8, 32, 128]}\n",
        "# hpt = {\"learning_rate\": [1e-2], \"batch_size\": [128]}\n",
        "keys, values = zip(*hpt.items())\n",
        "num_epoch = 1000\n",
        "i = 1\n",
        "for v in itertools.product(*values):\n",
        "  model_save_path_base = \"{}/models/HomemadeDataset2/Base/{}\".format(root_dir, i)\n",
        "  model_save_path_transformed = \"{}/models/HomemadeDataset2/Transformed/{}\".format(root_dir, i)\n",
        "  model_save_path_cross = \"{}/models/HomemadeDataset2/Cross/{}\".format(root_dir, i)\n",
        "  makedirs(model_save_path_base)\n",
        "  makedirs(model_save_path_transformed)\n",
        "  makedirs(model_save_path_cross)\n",
        "  experiment = dict(zip(keys, v))\n",
        "  print(experiment)\n",
        "  learning_rate = experiment[\"learning_rate\"]\n",
        "  batch_size = experiment[\"batch_size\"]\n",
        "\n",
        "  PrintDatetime(\"Started\")\n",
        "  homemade_train_test_path = \"{}/homemade_dataset2_resized\".format(train_test_path_base)\n",
        "  full_dataset = pd.read_csv(\"{}/labels.csv\".format(homemade_train_test_path))\n",
        "  az_dataset = full_dataset[full_dataset[\"LabelEncoded\"] <= 25]\n",
        "  train_dataset, test_val_dataset = train_test_split(az_dataset, test_size=0.2, random_state=0, shuffle=True)\n",
        "  test_dataset, val_dataset = train_test_split(test_val_dataset, test_size=0.5, random_state=0, shuffle=True)\n",
        "  train_dataset.to_csv(\"{}/train_az.csv\".format(homemade_train_test_path))\n",
        "  test_dataset.to_csv(\"{}/test_az.csv\".format(homemade_train_test_path))\n",
        "  val_dataset.to_csv(\"{}/val_az.csv\".format(homemade_train_test_path))\n",
        "  main(\"{}/train_az.csv\".format(homemade_train_test_path), \"{}/test_az.csv\".format(homemade_train_test_path), \"{}/val_az.csv\".format(homemade_train_test_path), learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epoch, model_save_path=model_save_path_base)\n",
        "  PrintDatetime()\n",
        "\n",
        "  homemade_train_test_path_transformed = \"{}/homemade_dataset2_transformed\".format(train_test_path_base)\n",
        "  full_dataset = pd.read_csv(\"{}/labels.csv\".format(homemade_train_test_path_transformed))\n",
        "  az_dataset = full_dataset[full_dataset[\"LabelEncoded\"] <= 25]\n",
        "  train_dataset, test_val_dataset = train_test_split(az_dataset, test_size=0.2, random_state=0, shuffle=True)\n",
        "  test_dataset, val_dataset = train_test_split(test_val_dataset, test_size=0.5, random_state=0, shuffle=True)\n",
        "  train_dataset.to_csv(\"{}/train_az.csv\".format(homemade_train_test_path_transformed))\n",
        "  test_dataset.to_csv(\"{}/test_az.csv\".format(homemade_train_test_path_transformed))\n",
        "  val_dataset.to_csv(\"{}/val_az.csv\".format(homemade_train_test_path_transformed))\n",
        "  PrintDatetime(\"Started training experiment\")\n",
        "  main(\"{}/train_az.csv\".format(homemade_train_test_path_transformed), \"{}/test_az.csv\".format(homemade_train_test_path_transformed), \"{}/val_az.csv\".format(homemade_train_test_path_transformed), learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epoch, model_save_path=model_save_path_transformed)\n",
        "  PrintDatetime()\n",
        "\n",
        "  PrintDatetime(\"Started training experiment\")\n",
        "  main(\"{}/train_az.csv\".format(homemade_train_test_path), \"{}/test_az.csv\".format(homemade_train_test_path_transformed), \"{}/val_az.csv\".format(homemade_train_test_path_transformed), learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epoch, model_save_path=model_save_path_cross)\n",
        "  PrintDatetime()\n",
        "\n",
        "\n",
        "  i += 1\n",
        "\n",
        "PrintDatetime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOYlDnh7gFkC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}